# Rule of thumb:
Sigma=sd(X)		# estimate the variance first
h.rot=1.06*Sigma*N^{-1/5} # calculates the rule-of-thumb bandwidth
h.rot;
dens1=npudens(bws=h.rot, X)	# estimate the density with this bandwidth
plot(dens1, main="Rule of thumb")
dens2=npudens(bws=4, X)		# oversmooth the density
plot(dens2, main= "Oversmoothed")
dens3=npudens(bws=0.3, X)	# undersmooth the density
plot(dens3, main="Undersmoothed")
h.cv=npudensbw(X, bwmethod="cv.ls")	# least squares cross validation.
# Need first to calculate the bandwidth
dens4=npudens(bws=h.cv)			# Now calculate the density
plot(dens4, main ="Cross validation")
#### ALTERNATIVE PLOT
True.dens=0.5*as.numeric(X<0)*dnorm(X, mean=-5, sd=3) + 0.5*as.numeric(X>=0)*dnorm(X, mean=5, sd=3)		# calculates the true density
Max=max(fitted(dens1), fitted(dens2), fitted(dens3), fitted(dens4))
# We need "Max" to increase the Y-range included in the plot
# So that all 4 curves fit in.
plot(X, True.dens, ylim=c(0, Max))
points(X, fitted(dens1), col=2)
points(X, fitted(dens2), col=3)
points(X, fitted(dens3), col=4)
points(X, fitted(dens4), col=5)
### Project Pension - Advanced Econometrics Methods, HSG
# librarys
library(readr)
library(zoo)
library(stats)
library(TSPred)
library(forecast)
library(lubridate)
library(data.table)
library(tidyverse)
library(hdm)
library(GGally)
library(ggcorrplot)
filter <- dplyr::filter
select <- dplyr::select
ggpairs <- GGally::ggpairs
ggcorrplot <- ggcorrplot::ggcorrplot
# setwd("C:/Users/eriks/Desktop/MiQE_F/Advanced Econometrics Methods/project") # setwd
# source("functions.R") # functions
outpath = "./output/" # output
datapath = "./data/" # data files (input datafile from package)
# Import Data
View(data("pension"))
mydata <- as.data.frame(pension)
# Descriptives
colnames(mydata)
key_vars=c("p401","e401","a401","tw")
financial_vars = c("inc","tfa","ira","net_tfa","nifa","net_nifa","net_n401")
other_controls_with_key_vars = c("age","fsize","marr","db","hown","educ","male","twoearn","hmort","hequity","hval")
# question: what are the i1-7 and a1-7 variables?
summary(mydata)
for (i in 1:ncol(mydata)){
png(file=paste0(outpath,"hist_",colnames(mydata)[i],".png"),
width=600, height=350)
hist(mydata[,i], main = paste("Hist for",colnames(mydata)[i]))
dev.off()
}
summary(is.na(mydata))
# Correlations
ggpairs(mydata[,key_vars])+
ggtitle(paste("Correlations Variables - Key Vars"))
ggsave(file=paste0(outpath,"corr_plot_key_vars",".png"),  width=6, height=4, dpi=300)
ggpairs(mydata[,c(key_vars, financial_vars)])+
ggtitle(paste("Correlations Variables - Financial Vars") )
ggsave(file=paste0(outpath,"corr_plot_key_vars",".png"),  width=6, height=4, dpi=300)
ggpairs(mydata[,c(key_vars,other_controls_with_key_vars)])+
ggtitle(paste("Correlations Variables - Other Control Vars") )
ggsave(file=paste0(outpath,"corr_plot_control_vars",".png"),  width=6, height=4, dpi=300)
ggcorrplot(cor(mydata[,c(key_vars,financial_vars,other_controls_with_key_vars)], method="pearson"), tl.cex=6) +
ggtitle(paste("Corr Matrix"))
ggsave(file=paste0(outpath,"corr_matrix_all",".png"),  width=6, height=4, dpi=300)
summary(pension$a401)
summary(mydata)
inc = log(mydata$inc)
inc
summary(inc)
count(mydata$inc<0)
count(mydata$inc<rep(0,nrow(mydata)))
count(mydata$inc<rep(0,nrow(mydata)))
mydata$inc
mydata$inc>0
sum(mydata$inc<0)
sum(mydata$p401 == 1 & mydata$e401)
sum(mydata$p401 == 1 & mydata$e401==1)
sum(mydata$p401 == 0 & mydata$e401==1)
sum(mydata$p401 == 0 & mydata$e401==0)
sum(mydata$p401 == 1 & mydata$e401==0)
mydata$eq_check = -mydata$hmort+mydata$hval
sum(mydata$eq_check==mydata$hequity)
sum(mydata$eq_check!=mydata$hequity)
hown_check = mydata$hequity > 0
sum(hown_check==mydata$hown)
sum(hown_check!=mydata$hown)
hown_check = mydata$hequity >= 0
sum(hown_check==mydata$hown)
sum(hown_check!=mydata$hown)
hown_check = mydata$hval  > 0
sum(hown_check==mydata$hown)
sum(hown_check!=mydata$hown)
summary(mydata$hval)
sum(mydata$fsize==2 & mydata$twoearn==1)
mydata_transform <- filter(mydata_transform, inc >= 0)
mydata_transform <- mydata
mydata_transform <- filter(mydata_transform, inc >= 0)
nrow(mydata_transform)
nrow(mydata)
sum(mydata$fsize==1 & mydata$twoearn==1)
educ_dummy_check = mydata$col+ mydata$smcol + mydata$hs + mydata$nohs
summary(educ_dummy_check)
sum(mydata$hequity==0)
sum(mydata$hown==0)
sum(mydata$hown==1)
sum(mydata$hequity==1)
sum(mydata$hequity==0)+ sum(mydata$hown==1)
all(educ_dummy_check2==mydata$nohs)
print("All education Dummys sum up to 1?")
mean(educ_dummy_check)
educ_dummy_check2 = mydata$educ<12
all(educ_dummy_check2==mydata$nohs)
?scale
# ! Hint2: add newly created continuous variables to the vector
continuous_vars = c("a401","tw","tfa","ira","net_tfa","nifa","net_nifa","net_n401","inc","hmort","hequity","hval")
mydata_transform[,continuous_vars] = scale(mydata_transform[,continuous_vars])
View(mydata_transform)
### Project Pension - Advanced Econometrics Methods, HSG
# librarys
library(readr)
library(zoo)
library(stats)
library(TSPred)
library(forecast)
library(lubridate)
library(data.table)
library(tidyverse)
library(hdm)
library(GGally)
library(ggcorrplot)
filter <- dplyr::filter
select <- dplyr::select
ggpairs <- GGally::ggpairs
ggcorrplot <- ggcorrplot::ggcorrplot
# setwd("C:/Users/eriks/Desktop/MiQE_F/Advanced Econometrics Methods/project") # setwd
# source("functions.R") # functions
outpath = "./output/" # output
datapath = "./data/" # data files (input datafile from package)
# Import Data
View(data("pension"))
mydata <- as.data.frame(pension)
# Data overview
# Descriptives
colnames(mydata)
key_vars=c("p401","e401","a401","tw")
financial_vars = c("inc","tfa","tfa_he","ira","net_tfa","nifa","net_nifa","net_n401")
other_controls_with_key_vars = c("age","fsize","marr","db","hown","educ","male","twoearn","hmort","hequity","hval")
# question: what are the i1-7 and a1-7 variables?
summary(mydata)
for (i in 1:ncol(mydata)){
png(file=paste0(outpath,"hist_",colnames(mydata)[i],".png"),
width=600, height=350)
hist(mydata[,i], main = paste("Hist for",colnames(mydata)[i]))
dev.off()
}
summary(is.na(mydata))
# Correlations
ggpairs(mydata[,key_vars])+
ggtitle(paste("Correlations Variables - Key Vars"))
ggsave(file=paste0(outpath,"corr_plot_key_vars",".png"),  width=6, height=4, dpi=300)
ggpairs(mydata[,c(key_vars, financial_vars)])+
ggtitle(paste("Correlations Variables - Financial Vars") )
ggsave(file=paste0(outpath,"corr_plot_key_vars",".png"),  width=6, height=4, dpi=300)
ggpairs(mydata[,c(key_vars,other_controls_with_key_vars)])+
ggtitle(paste("Correlations Variables - Other Control Vars") )
ggsave(file=paste0(outpath,"corr_plot_control_vars",".png"),  width=6, height=4, dpi=300)
ggcorrplot(cor(mydata[,c(key_vars,financial_vars,other_controls_with_key_vars)], method="pearson"), tl.cex=6) +
ggtitle(paste("Corr Matrix"))
ggsave(file=paste0(outpath,"corr_matrix_all",".png"),  width=6, height=4, dpi=300)
inc = log(mydata$inc)
# Plausibility Checks
# home value variables
mydata$eq_check = -mydata$hmort+mydata$hval
print("Home Equity Check")
sum(mydata$eq_check==mydata$hequity)
sum(mydata$eq_check!=mydata$hequity)
hown_check = mydata$hval > 0
print("Home Owner Check")
sum(hown_check==mydata$hown)
sum(hown_check!=mydata$hown)
# education dummies
educ_dummy_check = mydata$col+ mydata$smcol + mydata$hs + mydata$nohs
print("All education Dummys sum up to 1?")
mean(educ_dummy_check)
educ_dummy_check2 = mydata$educ<12
print("Non-High-School Dummy constructed via education years")
all(educ_dummy_check2==mydata$nohs)
######## TO DO, wealth vars didnt work out yet ############
# replicate fta
mydata$tfa_check = mydata$a401+mydata$nifa+mydata$ira
sum(mydata$tfa_check==mydata$tfa)
sum(mydata$tfa_check!=mydata$tfa)
# replicate net fin assets
mydata$nifa_check = mydata$a401 + mydata$net_n401
hist(mydata$nifa_check-mydata$nifa)
sum(mydata$nifa_check==mydata$nifa)
sum(mydata$nifa_check!=mydata$nifa)
# replicate total wealth: not possible since value of bus,property = value_other etc is missing. Can generate it
mydata$value_other = mydata$tw - mydata$nifa - mydata$hequity
sum(mydata$tw_check==mydata$tfa)
sum(mydata$tw_check!=mydata$tfa)
############################################
#### Data Transformation ####
mydata_transform <- mydata
# Remove observations and invalid values
# drop observations with negative income (only 2 obs, therefore drop outliers to avoid fitting to them)
mydata_transform <- filter(mydata_transform, inc >= 0)
# New variables
# family variable
mydata_transform$busy_couple = mydata_transform$fsize==2 & mydata_transform$twoearn==1
# Variable transformations
# Dummies for cutoffs
mydata_transform = mutate(mydata_transform, hmort_dummy = hmort>0) # mortgage dummy
mydata_transform = mutate(mydata_transform, hequity_dummy_neg = hequity<0) # hequity dummy negative
mydata_transform = mutate(mydata_transform, hequity_dummy = hequity>0) # hequity dummy
# Standardize continuous variables.
# ! Hint: need to do all "content-related" variable transformations before this step.
# ! Hint2: add newly created continuous variables to the vector
continuous_vars = c("a401","tw","tfa","ira","net_tfa","tfa_he", "nifa","net_nifa","net_n401","inc","hmort","hequity","hval")
mydata_transform[,continuous_vars] = scale(mydata_transform[,continuous_vars])
# Drop Variables
mydata_transform = select(mydata_transform, -zhat)    # remove IV variable
mydata_transform = select(mydata_transform, -nohs)  # no high school as reference category
# family variable
mydata_transform$busy_couple = as.numeric(mydata_transform$fsize==2 & mydata_transform$twoearn==1)
mydata_transform$busy_couple
colnames(mydata_transform)
library(readxl)
### Project: Effect of Crime on GDP-Growth - Criminology, HSG
##### Preamble ####
## librarys
library(readr)
library(zoo)
library(stats)
library(TSPred)
library(forecast)
library(lubridate)
library(data.table)
library(tidyverse)
library(hdm)
library(GGally)
library(ggcorrplot)
library(xtable)
library(fastDummies)
library(pcaMethods) # different pca-methods to deal with missing values
library(readxl)
## functions
filter <- dplyr::filter
select <- dplyr::select
ggpairs <- GGally::ggpairs
ggcorrplot <- ggcorrplot::ggcorrplot
## paths
setwd("D:/GitHub/crime_on_gdp") # setwd
outpath <- "./output/" # output
plots <- "./output/plots/"
tables <- "./output/tables/"
datapath <- "./data/" # data files (input datafile from package)
####  1) Import Data ####
# crime data (parsing errors are transformation of ; to NA)
crime_data_original <- read_csv("data/crim_off_cat__custom_128689_20201028_155532.csv",
col_types = cols(`2008` = col_number(),
`2009` = col_number(), `2010` = col_number(),
`2011` = col_number(), `2012` = col_number(),
`2013` = col_number(), `2014` = col_number(),
`2015` = col_number(), `2016` = col_number(),
`2017` = col_number(), `2018` = col_number()))
# corruption data
#csvs
CPI_2008 <- read_csv("D:/GitHub/crime_on_gdp/data/corruption/CPI-Archive-2008-2.csv")
CPI_2009 <- read_csv("D:/GitHub/crime_on_gdp/data/corruption/CPI-2009-new_200601_120052.csv")
CPI_2010 <- read_csv("D:/GitHub/crime_on_gdp/data/corruption/CPI-2010-new_200601_105629.csv")
CPI_2011 <- read_csv("D:/GitHub/crime_on_gdp/data/corruption/CPI-2011-new_200601_104308.csv")
CPI_2012 <- read_delim("D:/GitHub/crime_on_gdp/data/corruption/CPI2012_Results.csv",
";", escape_double = FALSE, trim_ws = TRUE)
#xlsx
# controls
#### 2) Preprocessing Crime Data ####
crime_data <- crime_data_original
colnames(crime_data)[1] <- c("id_vars")
# Split first variable string
str_split_first_col <- str_split(crime_data$id_vars,";",simplify=FALSE)
# crime_data$freq <- NA # freq only has possible value "A"
crime_data$iccs <- NA
crime_data$unit <- NA
crime_data$country <- NA
for (i in 1:nrow(crime_data)){
# crime_data$freq[i] <- str_split_first_col[[i]][1] # freq only has possible value "A"
crime_data$iccs[i] <- str_split_first_col[[i]][2]
crime_data$unit[i] <- str_split_first_col[[i]][3]
crime_data$country[i] <- str_split_first_col[[i]][4]
}
crime_data <- select(crime_data, -id_vars) %>%
relocate(iccs, .before='2008') %>%
relocate(unit, after=iccs) %>%
relocate(country, after=iccs)
# ony take rates / 100.000 and drop num variable
crime_data <- filter(crime_data, unit=="P_HTHAB") %>%
select(-unit)
# transform iccs to crime
iccs_to_crime <- cbind(paste0("ICCS",c("0101","0102","02011","020221","0301","03011","03012",
"0401","0501","05012","0502","050211","0601")),
c("intentional_homicide_1","attempted_intentional_homicide_1",
"assault_2","kidnapping_2","sexual_violence_3","rape_3","sexual_assault_3",
"robbery_4","burglary_5","burgraly_private_residence_5",
"theft_5","theft_motor_cycle_5","drugs_6"))
.fun_iccs_to_crime <- function(x,crime_vector){
return(crime_vector[x])
}
index_iccs <- match(crime_data$iccs, iccs_to_crime[,1])
crime_data$type_of_crime <- unlist(lapply(index_iccs,.fun_iccs_to_crime, crime_vector=iccs_to_crime[,2]))
main_crimes <-  c("intentional_homicide_1",
"assault_2","sexual_violence_3",
"robbery_4","burglary_5",
"theft_5","drugs_6")
# change years from wide to long
crime_data <- pivot_longer(crime_data, cols = c("2008","2009","2010","2011","2012","2013","2014","2015","2016","2017","2018"),
names_to = "year")
# change crime from long to wide
crime_data <- pivot_wider(crime_data,id_cols = c("country","year"),names_from = "type_of_crime",values_from = "value")
summary(crime_data)
summary(is.na(crime_data))
# create crime growth rates
# idea for creating a crime index:
# check for missing values & create subset with no NAs for main_crimes
summary(!is.na(crime_data$intentional_homicide_1) & !is.na(crime_data$assault_2) & !is.na(crime_data$rape_3) & !is.na(crime_data$robbery_4) & !is.na(crime_data$burglary_5) &  !is.na(crime_data$theft_5) & !is.na(crime_data$drugs_6))
crime_data_no_na_main_crimes <- crime_data[!is.na(crime_data$intentional_homicide_1) & !is.na(crime_data$assault_2) & !is.na(crime_data$rape_3) & !is.na(crime_data$robbery_4) & !is.na(crime_data$burglary_5) &  !is.na(crime_data$theft_5) & !is.na(crime_data$drugs_6),]
table(crime_data$country)
table(crime_data_no_na_main_crimes$country)
#### 3) Descriptives Crime ####
ggplot(data=crime_data) +
geom_line(aes(x=year,y=intentional_homicide_1, group = as.factor(country),color = country))+
theme_bw()+
theme(legend.position = "bottom", legend.box.background = element_rect(colour = "black"))+
ggtitle("intentional_homicide_1")
ggplot(data=crime_data) +
geom_line(aes(x=year,y=assault_2, group = as.factor(country),color = country))+
theme_bw()+
theme(legend.position = "bottom", legend.box.background = element_rect(colour = "black"))+
ggtitle("assault_2")
ggplot(data=crime_data) +
geom_line(aes(x=year,y=sexual_violence_3, group = as.factor(country),color = country))+
theme_bw()+
theme(legend.position = "bottom", legend.box.background = element_rect(colour = "black"))+
ggtitle("sexual_violence_3")
ggplot(data=crime_data) +
geom_line(aes(x=year,y=robbery_4, group = as.factor(country),color = country))+
theme_bw()+
theme(legend.position = "bottom", legend.box.background = element_rect(colour = "black"))+
ggtitle("robbery_4")
ggplot(data=crime_data) +
geom_line(aes(x=year,y=burglary_5, group = as.factor(country),color = country))+
theme_bw()+
theme(legend.position = "bottom", legend.box.background = element_rect(colour = "black"))+
ggtitle("burglary_5")
ggplot(data=crime_data) +
geom_line(aes(x=year,y=theft_5, group = as.factor(country),color = country))+
theme_bw()+
theme(legend.position = "bottom", legend.box.background = element_rect(colour = "black"))+
ggtitle("theft_5")
ggplot(data=crime_data) +
geom_line(aes(x=year,y=drugs_6, group = as.factor(country),color = country))+
theme_bw()+
theme(legend.position = "bottom", legend.box.background = element_rect(colour = "black"))+
ggtitle("drugs_6")
CPI_2014 <- read_delim("data/corruption/CPI 2014_FullDataSet.csv",
";", escape_double = FALSE, trim_ws = TRUE)
CPI_2015<- read_delim("data/corruption/CPI_2015_FullDataSet.csv",
";", escape_double = FALSE, trim_ws = TRUE)
CPI_2016 <- read_delim("data/corruption/CPI_2016_FullDataSet.csv",
";", escape_double = FALSE, trim_ws = TRUE)
CPI_2017 <- read_delim("data/corruption/CPI_2017_FullDataSet.csv",
";", escape_double = FALSE, trim_ws = TRUE)
CPI_2018 <- read_delim("data/corruption/CPI_2018_FullDataSet.csv",
";", escape_double = FALSE, trim_ws = TRUE)
getwd()
CPI_2014 <- read_delim("./data/corruption/CPI 2014_FullDataSet.csv",
";", escape_double = FALSE, trim_ws = TRUE)
CPI_2015<- read_delim("./data/corruption/CPI_2015_FullDataSet.csv",
";", escape_double = FALSE, trim_ws = TRUE)
CPI_2016 <- read_delim("./data/corruption/CPI_2016_FullDataSet.csv",
";", escape_double = FALSE, trim_ws = TRUE)
CPI_2017 <- read_delim("./data/corruption/CPI_2017_FullDataSet.csv",
";", escape_double = FALSE, trim_ws = TRUE)
CPI_2018 <- read_delim("./data/corruption/CPI_2018_FullDataSet.csv",
";", escape_double = FALSE, trim_ws = TRUE)
##### Preamble ####
## librarys
library(readr)
library(zoo)
library(stats)
library(TSPred)
library(forecast)
library(lubridate)
library(data.table)
library(tidyverse)
library(hdm)
library(GGally)
library(ggcorrplot)
library(xtable)
library(fastDummies)
library(pcaMethods) # different pca-methods to deal with missing values
library(readxl)
## functions
filter <- dplyr::filter
select <- dplyr::select
ggpairs <- GGally::ggpairs
ggcorrplot <- ggcorrplot::ggcorrplot
## paths
setwd("D:/GitHub/crime_on_gdp") # setwd
outpath <- "./output/" # output
plots <- "./output/plots/"
tables <- "./output/tables/"
datapath <- "./data/" # data files (input datafile from package)
####  1) Import Data ####
# crime data (parsing errors are transformation of ; to NA)
crime_data_original <- read_csv("data/crim_off_cat__custom_128689_20201028_155532.csv",
col_types = cols(`2008` = col_number(),
`2009` = col_number(), `2010` = col_number(),
`2011` = col_number(), `2012` = col_number(),
`2013` = col_number(), `2014` = col_number(),
`2015` = col_number(), `2016` = col_number(),
`2017` = col_number(), `2018` = col_number()))
# corruption data
#csvs
CPI_2008 <- read_csv("D:/GitHub/crime_on_gdp/data/corruption/CPI-Archive-2008-2.csv")
CPI_2014 <- read_delim("data/corruption/CPI 2014_FullDataSet.csv",
";", escape_double = FALSE, trim_ws = TRUE)
CPI_2014 <- read_delim("data/corruption/CPI 2014_FullDataSet.csv",
";", escape_double = FALSE, trim_ws = TRUE)
CPI_2015<- read_delim("data/corruption/CPI_2015_FullDataSet.csv",
";", escape_double = FALSE, trim_ws = TRUE)
CPI_2016 <- read_delim("data/corruption/CPI_2016_FullDataSet.csv",
";", escape_double = FALSE, trim_ws = TRUE)
CPI_2017 <- read_delim("data/corruption/CPI_2017_FullDataSet.csv",
";", escape_double = FALSE, trim_ws = TRUE)
CPI_2018 <- read_delim("data/corruption/CPI_2018_FullDataSet.csv",
";", escape_double = FALSE, trim_ws = TRUE)
CPI_2014 <- read_delim("data/corruption/CPI2014_FullDataSet.csv",
";", escape_double = FALSE, trim_ws = TRUE)
CPI_2015<- read_delim("data/corruption/CPI2015_FullDataSet.csv",
";", escape_double = FALSE, trim_ws = TRUE)
CPI_2016 <- read_delim("data/corruption/CPI2016_FullDataSet.csv",
";", escape_double = FALSE, trim_ws = TRUE)
CPI_2017 <- read_delim("data/corruption/CPI2017_FullDataSet.csv",
";", escape_double = FALSE, trim_ws = TRUE)
CPI_2018 <- read_delim("data/corruption/CPI2018_FullDataSet.csv",
";", escape_double = FALSE, trim_ws = TRUE)
CPI_2014 <- read_delim("data/corruption/CPI2014_FullDataSet.csv",
";", escape_double = FALSE, trim_ws = TRUE)
CPI_2015<- read_delim("data/corruption/CPI2015_FullDataSet.csv",
";", escape_double = FALSE, trim_ws = TRUE)
CPI_2016 <- read_delim("data/corruption/CPI2016_FullDataSet.csv",
";", escape_double = FALSE, trim_ws = TRUE)
CPI_2017 <- read_delim("data/corruption/CPI2017_FullDataSet.csv",
";", escape_double = FALSE, trim_ws = TRUE)
CPI_2018 <- read_delim("data/corruption/CPI2018_FullDataSet.csv",
";", escape_double = FALSE, trim_ws = TRUE)
## functions
filter <- dplyr::filter
select <- dplyr::select
ggpairs <- GGally::ggpairs
ggcorrplot <- ggcorrplot::ggcorrplot
## paths
setwd("D:/GitHub/crime_on_gdp") # setwd
outpath <- "./output/" # output
plots <- "./output/plots/"
tables <- "./output/tables/"
datapath <- "./data/" # data files (input datafile from package)
####  1) Import Data ####
# crime data (parsing errors are transformation of ; to NA)
crime_data_original <- read_csv("data/crim_off_cat__custom_128689_20201028_155532.csv",
col_types = cols(`2008` = col_number(),
`2009` = col_number(), `2010` = col_number(),
`2011` = col_number(), `2012` = col_number(),
`2013` = col_number(), `2014` = col_number(),
`2015` = col_number(), `2016` = col_number(),
`2017` = col_number(), `2018` = col_number()))
# corruption data
#csvs
CPI_2008 <- read_csv("D:/GitHub/crime_on_gdp/data/corruption/CPI-Archive-2008-2.csv")
CPI_2009 <- read_csv("D:/GitHub/crime_on_gdp/data/corruption/CPI-2009-new_200601_120052.csv")
CPI_2010 <- read_csv("D:/GitHub/crime_on_gdp/data/corruption/CPI-2010-new_200601_105629.csv")
CPI_2011 <- read_csv("D:/GitHub/crime_on_gdp/data/corruption/CPI-2011-new_200601_104308.csv")
CPI_2012 <- read_delim("D:/GitHub/crime_on_gdp/data/corruption/CPI2012_Results.csv",
";", escape_double = FALSE, trim_ws = TRUE)
CPI_2014 <- read_delim("data/corruption/CPI2014_FullDataSet.csv",
";", escape_double = FALSE, trim_ws = TRUE)
CPI_2015<- read_delim("data/corruption/CPI2015_FullDataSet.csv",
";", escape_double = FALSE, trim_ws = TRUE)
CPI_2016 <- read_delim("data/corruption/CPI2016_FullDataSet.csv",
";", escape_double = FALSE, trim_ws = TRUE)
CPI_2017 <- read_delim("data/corruption/CPI2017_FullDataSet.csv",
";", escape_double = FALSE, trim_ws = TRUE)
CPI_2018 <- read_delim("data/corruption/CPI2018_FullDataSet.csv",
";", escape_double = FALSE, trim_ws = TRUE)
#xlsx
CPI_2013 <- read_excel("data/corruption/CPI2013_GLOBAL_WithDataSourceScores.xls")
View(CPI_2008)
View(CPI_2013)
View(CPI_2010)
View(CPI_2016)
